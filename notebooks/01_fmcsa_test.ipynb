{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5337d0fe",
   "metadata": {},
   "source": [
    "# Import FMCSA PFDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d9a9a40-262f-4f98-b211-5062364467cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found file at: ../data/raw/fmcsa_op_training.pdf\n",
      "ğŸ‰ Success! Loaded 1092 pages.\n",
      "--- Content of Page 1 ---\n",
      "eFOTM Compliance Manual      Jan 4th,2 0 2 5\n",
      "Page  1  \n",
      "Compliance Manual\n",
      "For\n",
      "eFOTM Redevelopment\n",
      "Federal Motor Carrier Safety Administration (FMCSA)\n",
      "U.S. Department of Transportation...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 1. Define the path (adjust if your PDF has a different name)\n",
    "pdf_path = \"../data/raw/fmcsa_op_training.pdf\"\n",
    "\n",
    "# 2. Check if file exists\n",
    "if os.path.exists(pdf_path):\n",
    "    print(f\"âœ… Found file at: {pdf_path}\")\n",
    "    \n",
    "    # 3. Load the PDF\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages = loader.load()\n",
    "        print(f\"ğŸ‰ Success! Loaded {len(pages)} pages.\")\n",
    "        print(f\"--- Content of Page 1 ---\\n{pages[0].page_content[:500]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading PDF: {e}\")\n",
    "else:\n",
    "    print(f\"âŒ File NOT found at: {pdf_path}\")\n",
    "    print(f\"ğŸ“‚ Current folder is: {os.getcwd()}\")\n",
    "    print(f\"ğŸ“‚ Files in parent folder: {os.listdir('..')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a62f22",
   "metadata": {},
   "source": [
    "# Split the Text into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8275971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”ª Splitting the document...\n",
      "ğŸ‰ Created 4404 text chunks from 1092 pages.\n",
      "--- Example Chunk 1 ---\n",
      "eFOTM Compliance Manual      Jan 4th,2 0 2 5\n",
      "Page  1  \n",
      "Compliance Manual\n",
      "For\n",
      "eFOTM Redevelopment\n",
      "Federal Motor Carrier Safety Administration (FMCSA)\n",
      "U.S. Department of Transportation\n",
      "--- Example Chunk 2 ---\n",
      "eFOTM Compliance Manual                                                                      Jan 4th,2 0 2 5\n",
      "Page | 2\n",
      "Table of Contents\n",
      "1.0 Compliance Manual .......................................................................................................7 \n",
      "1.1 Stage 1-Monthly Intervention Selection & Carrier Assignment ........................................... 7 \n",
      "1.1.1 Stage 1 - Introduction ..................................................................................................................... 7 \n",
      "1.1.2 Safety Measurement System Assesses Carrier Performance, Generates Warning Letters, and \n",
      "Tracks Acute and Critical Violations....................................................................................................... 7 \n",
      "1.1.2.1 On-Road Safety Performance................................................................................................... 8\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. Configure the splitter\n",
    "# chunk_size=1000: Roughly a few paragraphs\n",
    "# chunk_overlap=200: Keeps context between cuts so sentences aren't cut in half\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "# 2. Split the document\n",
    "print(\"ğŸ”ª Splitting the document...\")\n",
    "all_splits = text_splitter.split_documents(pages)\n",
    "\n",
    "# 3. Check the results\n",
    "print(f\"ğŸ‰ Created {len(all_splits)} text chunks from {len(pages)} pages.\")\n",
    "print(f\"--- Example Chunk 1 ---\\n{all_splits[0].page_content}\")\n",
    "print(f\"--- Example Chunk 2 ---\\n{all_splits[1].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb611c",
   "metadata": {},
   "source": [
    "# Embed/Save the Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a1f327e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸  Loading FastEmbed model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Github\\fmcsa_assistant\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded!\n",
      "ğŸš€ Starting processing of 4404 chunks in batches of 100...\n",
      "ğŸ’¾ Saved 100/4404 chunks (2.3%)\n",
      "ğŸ’¾ Saved 200/4404 chunks (4.5%)\n",
      "ğŸ’¾ Saved 300/4404 chunks (6.8%)\n",
      "ğŸ’¾ Saved 400/4404 chunks (9.1%)\n",
      "ğŸ’¾ Saved 500/4404 chunks (11.4%)\n",
      "ğŸ’¾ Saved 600/4404 chunks (13.6%)\n",
      "ğŸ’¾ Saved 700/4404 chunks (15.9%)\n",
      "ğŸ’¾ Saved 800/4404 chunks (18.2%)\n",
      "ğŸ’¾ Saved 900/4404 chunks (20.4%)\n",
      "ğŸ’¾ Saved 1000/4404 chunks (22.7%)\n",
      "ğŸ’¾ Saved 1100/4404 chunks (25.0%)\n",
      "ğŸ’¾ Saved 1200/4404 chunks (27.2%)\n",
      "ğŸ’¾ Saved 1300/4404 chunks (29.5%)\n",
      "ğŸ’¾ Saved 1400/4404 chunks (31.8%)\n",
      "ğŸ’¾ Saved 1500/4404 chunks (34.1%)\n",
      "ğŸ’¾ Saved 1600/4404 chunks (36.3%)\n",
      "ğŸ’¾ Saved 1700/4404 chunks (38.6%)\n",
      "ğŸ’¾ Saved 1800/4404 chunks (40.9%)\n",
      "ğŸ’¾ Saved 1900/4404 chunks (43.1%)\n",
      "ğŸ’¾ Saved 2000/4404 chunks (45.4%)\n",
      "ğŸ’¾ Saved 2100/4404 chunks (47.7%)\n",
      "ğŸ’¾ Saved 2200/4404 chunks (50.0%)\n",
      "ğŸ’¾ Saved 2300/4404 chunks (52.2%)\n",
      "ğŸ’¾ Saved 2400/4404 chunks (54.5%)\n",
      "ğŸ’¾ Saved 2500/4404 chunks (56.8%)\n",
      "ğŸ’¾ Saved 2600/4404 chunks (59.0%)\n",
      "ğŸ’¾ Saved 2700/4404 chunks (61.3%)\n",
      "ğŸ’¾ Saved 2800/4404 chunks (63.6%)\n",
      "ğŸ’¾ Saved 2900/4404 chunks (65.8%)\n",
      "ğŸ’¾ Saved 3000/4404 chunks (68.1%)\n",
      "ğŸ’¾ Saved 3100/4404 chunks (70.4%)\n",
      "ğŸ’¾ Saved 3200/4404 chunks (72.7%)\n",
      "ğŸ’¾ Saved 3300/4404 chunks (74.9%)\n",
      "ğŸ’¾ Saved 3400/4404 chunks (77.2%)\n",
      "ğŸ’¾ Saved 3500/4404 chunks (79.5%)\n",
      "ğŸ’¾ Saved 3600/4404 chunks (81.7%)\n",
      "ğŸ’¾ Saved 3700/4404 chunks (84.0%)\n",
      "ğŸ’¾ Saved 3800/4404 chunks (86.3%)\n",
      "ğŸ’¾ Saved 3900/4404 chunks (88.6%)\n",
      "ğŸ’¾ Saved 4000/4404 chunks (90.8%)\n",
      "ğŸ’¾ Saved 4100/4404 chunks (93.1%)\n",
      "ğŸ’¾ Saved 4200/4404 chunks (95.4%)\n",
      "ğŸ’¾ Saved 4300/4404 chunks (97.6%)\n",
      "ğŸ’¾ Saved 4400/4404 chunks (99.9%)\n",
      "ğŸ’¾ Saved 4404/4404 chunks (100.0%)\n",
      "------------------------------------------------\n",
      "ğŸ‰ MISSION COMPLETE! Database fully saved to: ../data/chroma_db\n",
      "ğŸ“Š Final Check - Total vectors stored: 4404\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import FastEmbedEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import time\n",
    "\n",
    "# 1. Initialize the Local Model\n",
    "print(\"â¬‡ï¸  Loading FastEmbed model...\")\n",
    "embedding_model = FastEmbedEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "print(\"âœ… Model loaded!\")\n",
    "\n",
    "# 2. Setup the Database\n",
    "persist_directory = \"../data/chroma_db\"\n",
    "# Initialize the database immediately so we can add to it incrementally\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"fmcsa_regulations\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "# 3. Define Batch Size (Manageable chunks for your CPU)\n",
    "batch_size = 100 \n",
    "total_chunks = len(all_splits)\n",
    "\n",
    "print(f\"ğŸš€ Starting processing of {total_chunks} chunks in batches of {batch_size}...\")\n",
    "\n",
    "# 4. The Loop: Process and Save piece by piece\n",
    "for i in range(0, total_chunks, batch_size):\n",
    "    # Get the slice of documents for this batch\n",
    "    batch = all_splits[i : i + batch_size]\n",
    "    \n",
    "    # Add them to the database (this runs the embedding on CPU)\n",
    "    vector_store.add_documents(documents=batch)\n",
    "    \n",
    "    # Progress Update\n",
    "    current_count = min(i + batch_size, total_chunks)\n",
    "    print(f\"ğŸ’¾ Saved {current_count}/{total_chunks} chunks ({round(current_count/total_chunks*100, 1)}%)\")\n",
    "    \n",
    "    # Small pause to let your CPU cool down slightly (optional)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(f\"ğŸ‰ MISSION COMPLETE! Database fully saved to: {persist_directory}\")\n",
    "print(f\"ğŸ“Š Final Check - Total vectors stored: {vector_store._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5487c3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â“ Question: What are the requirements for a driver's daily log?\n",
      "ğŸ” Searching database...\n",
      "\n",
      "---------------- RESULTS ----------------\n",
      "\n",
      "ğŸ“„ [Source: ../data/raw/fmcsa_op_training.pdf]\n",
      "ğŸ“– Page: 606\n",
      "ğŸ“ Content Preview: be cited 395.8(a) or \n",
      "395.8(k)(2).  Driver must \n",
      "be given the opportunity to \n",
      "print current and prior \n",
      "seven days RODs at \n",
      "roadside. \n",
      "Hours of Service for Commercial Motor \n",
      "Vehicle Drivers; Regulatory Guidance \n",
      "Concerning Records of Duty Status \n",
      "Generated by Logging Software Programs \n",
      "(79 FR 39342)\n",
      "...\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“„ [Source: ../data/raw/fmcsa_op_training.pdf]\n",
      "ğŸ“– Page: 600\n",
      "ğŸ“ Content Preview: device capable of recording a driverâ€™s duty status information accurately and automatically as required by \n",
      "49 CFR Â§ 395.15.  The device must be integrally synchronized with specific operations of the CMV in \n",
      "which it is installed and, at a minimum, the device must record engine use, road speed, mil...\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“„ [Source: ../data/raw/fmcsa_op_training.pdf]\n",
      "ğŸ“– Page: 201\n",
      "ğŸ“ Content Preview: provide steps for obtaining the drivers hours during a roadside inspection.\n",
      "x Software Manual- this manual may provide information about the set-up parameters for the system \n",
      "addressing data storage, when driving time starts being recorded (miles driven and/or time in drive \n",
      "gears), availability of ...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# STEP 4: The First Test (Run this AFTER processing finishes)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "query = \"What are the requirements for a driver's daily log?\"\n",
    "\n",
    "print(f\"â“ Question: {query}\")\n",
    "print(\"ğŸ” Searching database...\")\n",
    "\n",
    "# Search for the 3 most relevant chunks\n",
    "results = vector_store.similarity_search(query, k=3)\n",
    "\n",
    "print(\"\\n---------------- RESULTS ----------------\")\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\nğŸ“„ [Source: {doc.metadata.get('source', 'Unknown')}]\")\n",
    "    print(f\"ğŸ“– Page: {doc.metadata.get('page', 'Unknown')}\")\n",
    "    print(f\"ğŸ“ Content Preview: {doc.page_content[:300]}...\") # Show first 300 chars\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e201627f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Re-opening the database connection...\n",
      "âœ… Database loaded!\n",
      "âœ… API Key loaded safely from environment.\n",
      "ğŸ§  Connecting to Gemini 2.5 Flash...\n",
      "\n",
      "â“ Question: What are the requirements for a driver's daily log?\n",
      "ğŸ§  Thinking... (Sending chunks to Gemini 2.5)\n",
      "\n",
      "============================================================\n",
      "ğŸ¤– AI ANSWER:\n",
      "============================================================\n",
      "The electronically-generated display and output for a driver's daily log (Records of Duty Status or RODS) must meet the requirements in **49 CFR Â§ 395.8** and are treated as an alternative to paper logs.\n",
      "\n",
      "Additionally, drivers must be able to provide printouts of their logs at roadside:\n",
      "*   Drivers must be given the opportunity to print current and prior seven days of RODS at roadside if cited under 395.8(a) or 395.8(k)(2).\n",
      "*   If using logging software and an application device without electronic signature capabilities, the driver must be given the opportunity to print the current day's RODS at roadside.\n",
      "\n",
      "------------------------------------------------------------\n",
      "ğŸ“š SOURCES USED:\n",
      "- Page 606 (File: fmcsa_op_training.pdf)\n",
      "- Page 600 (File: fmcsa_op_training.pdf)\n",
      "- Page 201 (File: fmcsa_op_training.pdf)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv  # <-- The Safety Tool\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import FastEmbedEmbeddings\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 1. SETUP: Reload the Database\n",
    "print(\"ğŸ“‚ Re-opening the database connection...\")\n",
    "embedding_model = FastEmbedEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "persist_directory = \"../data/chroma_db\"\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"fmcsa_regulations\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "print(\"âœ… Database loaded!\")\n",
    "\n",
    "# 2. SETUP: Connect to Gemini (SECURELY) ğŸ”’\n",
    "load_dotenv()\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    print(\"âš ï¸ No .env file found. Running in Interactive Mode.\")\n",
    "    # The 'getpass' function hides what you type\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
    "else:\n",
    "    print(\"âœ… API Key loaded safely from environment.\")\n",
    "\n",
    "# --- THE FIX: Gemini 2.5 Flash ---\n",
    "print(\"ğŸ§  Connecting to Gemini 2.5 Flash...\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "# 3. BUILD: The Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# 4. ACTION: Ask the Question\n",
    "query = \"What are the requirements for a driver's daily log?\"\n",
    "print(f\"\\nâ“ Question: {query}\")\n",
    "print(\"ğŸ§  Thinking... (Sending chunks to Gemini 2.5)\")\n",
    "\n",
    "try:\n",
    "    response = qa_chain.invoke({\"query\": query})\n",
    "    \n",
    "    # 5. Print the Result\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ¤– AI ANSWER:\")\n",
    "    print(\"=\"*60)\n",
    "    print(response[\"result\"])\n",
    "\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"ğŸ“š SOURCES USED:\")\n",
    "    for doc in response[\"source_documents\"]:\n",
    "        source = doc.metadata.get('source', 'Unknown').split('/')[-1]\n",
    "        print(f\"- Page {doc.metadata.get('page')} (File: {source})\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d29194f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_fmcsa(question):\n",
    "    \"\"\"\n",
    "    Takes a question, searches the FMCSA database, and returns a sourced answer.\n",
    "    (Includes 'Off-By-One' fix for page numbers)\n",
    "    \"\"\"\n",
    "    print(f\"\\nâ“ Question: {question}\")\n",
    "    print(\"ğŸ§  Thinking...\")\n",
    "    \n",
    "    try:\n",
    "        # Run the chain\n",
    "        response = qa_chain.invoke({\"query\": question})\n",
    "        \n",
    "        # Print the Answer\n",
    "        print(\"\\n\" + \"ğŸ¤– AI ANSWER:\")\n",
    "        print(\"-\" * 20)\n",
    "        print(response[\"result\"])\n",
    "        \n",
    "        # Print Sources\n",
    "        print(\"\\n\" + \"ğŸ“š SOURCES:\")\n",
    "        seen_sources = set()\n",
    "        for doc in response[\"source_documents\"]:\n",
    "            source = doc.metadata.get('source', 'Unknown').split('/')[-1]\n",
    "            \n",
    "            # --- THE FIX IS HERE ---\n",
    "            # Grab the raw page number (default to -1 if missing)\n",
    "            raw_page = doc.metadata.get('page', -1)\n",
    "            \n",
    "            # Add 1 to convert \"Index 0\" to \"Page 1\"\n",
    "            human_page = raw_page + 1\n",
    "            \n",
    "            # De-duplicate references\n",
    "            ref = f\"{source} (Page {human_page})\"\n",
    "            if ref not in seen_sources:\n",
    "                print(f\"- {ref}\")\n",
    "                seen_sources.add(ref)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d0d73f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â“ Question: What defines a 'preventable accident'?\n",
      "ğŸ§  Thinking...\n",
      "\n",
      "ğŸ¤– AI ANSWER:\n",
      "--------------------\n",
      "Based on the provided text, an accident is considered **preventable** if there is any uncertainty in a report as to whether the driver could have avoided the accident.\n",
      "\n",
      "Key points defining a preventable accident:\n",
      "*   The determination focuses on whether the driver *could have avoided* the accident, not necessarily who \"caused\" it. These are separate issues.\n",
      "*   The motor carrier must present \"compelling evidence\" to prove an accident was *not* preventable.\n",
      "*   If police and insurance company reports fail to indicate when the driver became aware of a dangerous situation or how much time they had to react effectively, and there's uncertainty about avoidance, the accident must be considered preventable.\n",
      "\n",
      "ğŸ“š SOURCES:\n",
      "- fmcsa_op_training.pdf (Page 801)\n",
      "- fmcsa_op_training.pdf (Page 115)\n"
     ]
    }
   ],
   "source": [
    "# --- TEST IT OUT ---\n",
    "# Now you can ask anything instantly!\n",
    "ask_fmcsa(\"What defines a 'preventable accident'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdcab574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â“ Question: What is considered evidence of a preventable accident?\n",
      "ğŸ§  Thinking...\n",
      "\n",
      "ğŸ¤– AI ANSWER:\n",
      "--------------------\n",
      "The provided text does not explicitly list what is considered \"evidence of a preventable accident.\" Instead, it outlines the criteria and evidence required to determine if an accident is **non-preventable**.\n",
      "\n",
      "However, based on the context, an accident is considered preventable if:\n",
      "\n",
      "*   There is **any uncertainty** in a report as to whether the driver could have avoided the accident.\n",
      "*   The motor carrier fails to present \"compelling evidence\" on the issue of preventability (i.e., compelling evidence that the accident was non-preventable).\n",
      "*   Police and insurance company reports, which often fall short of the \"compelling evidence\" standard, do not clearly indicate when the driver became aware of a dangerous situation or had enough time to react effectively to avoid the accident.\n",
      "\n",
      "In essence, if the evidence does not compellingly prove that the driver could **not** have avoided the accident, it will be considered preventable. The determination focuses on whether the driver *could have avoided* the accident, which is a separate issue from who \"caused\" it.\n",
      "\n",
      "ğŸ“š SOURCES:\n",
      "- fmcsa_op_training.pdf (Page 801)\n",
      "- fmcsa_op_training.pdf (Page 116)\n",
      "- fmcsa_op_training.pdf (Page 796)\n"
     ]
    }
   ],
   "source": [
    "ask_fmcsa(\"What is considered evidence of a preventable accident?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54c31df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â“ Question: What are the main safety factors or pillars according to FMCSA?\n",
      "ğŸ§  Thinking...\n",
      "\n",
      "ğŸ¤– AI ANSWER:\n",
      "--------------------\n",
      "Based on the provided text, the FMCSA's main safety goals and methods, particularly through the COMPASS program, focus on:\n",
      "\n",
      "*   **Saving lives and improving the safety of commercial motor vehicles.**\n",
      "*   **Creating a single source for crucial safety data** via single sign-on access.\n",
      "*   **Improving data quality** to enable better, more informed decision making.\n",
      "*   **Providing actionable information and data.**\n",
      "*   **Optimizing FMCSA's business processes and improving the Agency's IT functionality.**\n",
      "\n",
      "ğŸ“š SOURCES:\n",
      "- fmcsa_op_training.pdf (Page 314)\n",
      "- fmcsa_op_training.pdf (Page 979)\n"
     ]
    }
   ],
   "source": [
    "ask_fmcsa(\"What are the main safety factors or pillars according to FMCSA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95f45de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â“ Question: Provide me with some examples of documents that may be used to prove violations of part 391\n",
      "ğŸ§  Thinking...\n",
      "\n",
      "ğŸ¤– AI ANSWER:\n",
      "--------------------\n",
      "Here are some examples of documents that may be used to prove violations of Part 391:\n",
      "\n",
      "*   Statement from a motor carrier official, driver, or other person responsible for compliance with Part 391.\n",
      "*   DQ Worksheet (potentially CAPRI DQ Worksheet), verified by a motor carrier official or other person responsible for compliance with Part 391.\n",
      "*   Driverâ€™s RODS (Records of Duty Status) and corresponding shipping paper/bill of lading.\n",
      "*   Vehicle registration showing GVWR or other documentary evidence proving that the vehicle was subject to Part 391.\n",
      "*   A statement from the motor carrier attesting to missing documents or, if applicable, utilizing a DQ Worksheet (or CAPRI DQ Worksheet) to have the motor carrier verify the lack of documents, if copies of documents/certificates required by Part 391 were unavailable or do not exist.\n",
      "*   Certified documents from State agencies.\n",
      "*   Photographs that support the violation.\n",
      "\n",
      "It's important to note that this list is not exhaustive, and other motor carrier documents can also be used to support a violation.\n",
      "\n",
      "ğŸ“š SOURCES:\n",
      "- fmcsa_op_training.pdf (Page 136)\n",
      "- fmcsa_op_training.pdf (Page 147)\n",
      "- fmcsa_op_training.pdf (Page 294)\n"
     ]
    }
   ],
   "source": [
    "ask_fmcsa(\"Provide me with some examples of documents that may be used to prove violations of part 391\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db3ab91",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa3829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
